{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd3d7bd",
   "metadata": {},
   "source": [
    "Teoría de Decisión Bayesiana\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49ee16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.signal import square\n",
    "from util import modula\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-delay",
   "metadata": {},
   "source": [
    "# Contraste de Hipótesis (o Test de Hipótesis).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36f25d6",
   "metadata": {},
   "source": [
    "\n",
    "# Decisión Bayesiana  -  Estimador óptimo.\n",
    "\n",
    "La definición del umbral de decisión ($\\delta$) depende, principalmente, del problema que se esté abordando. Pero definido un estimador, es válida la pregunta sobre cuál es el umbral óptimo de decisión.\n",
    "\n",
    "Habiendo definido oportunamente:\n",
    "\n",
    "$$\\begin{array}\\\\\n",
    "\\mathcal{H}_0: & la \\; clase \\; es \\; y =-1 \\\\\n",
    "\\mathcal{H}_1: & la \\; clase \\; es \\; y =1 \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "y suponiendo que se conocen las probabilidades $P(\\mathcal{H}_1 \\mid X)$ y $P(\\mathcal{H}_0 \\mid X)$, las cuales me indican la probabilidad de que pertenezca a cada clase una muestra $X \\in \\mathcal{X}$, es directo definir la política de decisión sobre a qué clase pertenece una muestra $X$:\n",
    "\n",
    "\n",
    "$$\\begin{array}\\\\\n",
    "Se\\;elige \\; \\mathcal{H}_0 & si &  P(\\mathcal{H}_0 \\mid X) >  P(\\mathcal{H}_1 \\mid X)\\\\\n",
    "Se\\;elige \\; \\mathcal{H}_1 & si &  P(\\mathcal{H}_1 \\mid X) >  P(\\mathcal{H}_0 \\mid X)\\\\ \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "de forma más resumida, escribimos lo anterior como sigue\n",
    "\n",
    "$$ P(\\mathcal{H}_0 \\mid X) \\mathop{\\gtrless}\\limits_{\\mathcal{H}_1}^{\\mathcal{H}_0} P(\\mathcal{H}_1 \\mid X)$$\n",
    "\n",
    "El problema radica en que estas probabilidades no se conocen, puesto que es posible conocer todos los posibles datos $X$,ya que el Corpus es un subconjunto de los posibles eventos. No obstante, aplicando el **Teorema de Bayes** la ecuación anterior se puede escribir como:\n",
    "\n",
    "$$P( \\mathcal{H}_0) \\; P(X \\mid \\mathcal{H}_0) \\mathop{\\gtrless}\\limits_{\\mathcal{H}_1}^{\\mathcal{H}_0} P( \\mathcal{H}_1) \\; P(X \\mid \\mathcal{H}_1)$$\n",
    "\n",
    "donde estas probabilidades pueden estimarse a partir del Corpus de datos $\\mathcal{X}$.\n",
    "\n",
    "Si el corpus es representativo del espacio muestral, entonces a partir de $X \\in \\mathcal{X}$ y sus categorías $y \\in \\mathcal{Y}$ se pueden estimar las probabilidades $P(\\mathcal{H}_0)$ contando la cantidad de elementos de la categoría $y=-1$, igualmente $P(\\mathcal{H}_0)$ para la categoría $y=1$.\n",
    "\n",
    "Esta estimación es muy dependiente del diseño del corpus, y por lo tanto suelen ser equiprobables, No obstante, una vez puesto el estimador en producción, puede variar. Por ejemplo, si el estimador es parte de una alarma, el corpus puede mostrar equiprobabilidad, cuando la realidad es diferente. \n",
    "\n",
    "Por otra parte, conociendo el conjunto de datos, $\\mathcal{X}$ y el conjunto de clasificación de los datos, $\\mathcal{Y}$,  se pueden considerar conocidas las probabilidades condicionales $P(X / \\mathcal{H}_0)$ y $P(X / \\mathcal{H}_1)$. Aquí la estimación depende de cuán bien representado esté en $\\mathcal{X}$ el espacio muestral.  \n",
    "\n",
    "Para evitar ese problema, se puede estimar a partir de un modelo de distribución de probabilida. Uno muy útil, puede ser considerar una distribución Gaussiana:\n",
    "\n",
    "$$\\begin{array}\\\\\n",
    "P(X / \\mathcal{H}_0): \\mathcal{N}(\\mu_0, \\Sigma_0) & \\rightarrow & f_{X/\\mathcal{H}_0}(x) = \\frac{1}{(2\\pi)^\\frac{n}{2} |\\Sigma_0|^\\frac{1}{2}} e^{-\\frac{1}{2} (x-\\mu_0)^T \\Sigma_0^{-1} (x-\\mu_0)}\\\\\n",
    "P(X / \\mathcal{H}_1): \\mathcal{N}(\\mu_1, \\Sigma_1) & \\rightarrow & f_{X/\\mathcal{H}_1}(x) = \\frac{1}{(2\\pi)^\\frac{n}{2} |\\Sigma_1|^\\frac{1}{2}} e^{-\\frac{1}{2} (x-\\mu_1)^T \\Sigma_1^{-1} (x-\\mu_1)}\n",
    "\\end{array}$$\n",
    "\n",
    "\n",
    "siendo $\\mu_0$, $\\Sigma_0$, $\\mu_1$, $\\Sigma_1$ las medias y matrices de covarianzas para $P(X \\mid \\mathcal{H}_0)$ y $P(X \\mid \\mathcal{H}_1)$ respectivamente. **De todas maneras, para distribuciones gaussianas se debe correr un test de normalidad sobre los datos**. Esto último no se va a considerar aquí.\n",
    "\n",
    "Entonces, volviendo a considerar \n",
    "\n",
    "\n",
    "$$P( \\mathcal{H}_0) \\; P(X \\mid \\mathcal{H}_0) \\mathop{\\gtrless}\\limits_{\\mathcal{H}_1}^{\\mathcal{H}_0} P( \\mathcal{H}_1) \\; P(X \\mid \\mathcal{H}_1)$$\n",
    "\n",
    "se tiene también que,\n",
    "\n",
    "\n",
    "$$ \\frac{P(X \\mid \\mathcal{H}_1)}{P(X \\mid \\mathcal{H}_0)} \\mathop{\\gtrless}\\limits_{\\mathcal{H}_0}^{\\mathcal{H}_1}  \\frac{P(\\mathcal{H}_0)}{P( \\mathcal{H}_1)} = \\alpha$$\n",
    "\n",
    "\n",
    "donde denominamos $\\alpha\\in \\mathbb{R}_{\\geq 0}$ a la relación entre las probabilidades de las categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf71236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-builder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-entertainment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 309.844,
   "position": {
    "height": "40px",
    "left": "887px",
    "right": "20px",
    "top": "120px",
    "width": "325px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
